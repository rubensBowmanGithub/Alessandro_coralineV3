define({"topics" : [{"title":"Prerequisites","href":"datacollector\/UserGuide\/Destinations\/DeltaLake.html#concept_xnp_y5f_dlb","attributes": {"data-id":"concept_xnp_y5f_dlb",},"menu": {"hasChildren":true,},"tocID":"concept_xnp_y5f_dlb-d46e145382","next":"concept_xnp_y5f_dlb-d46e145382",},{"title":"Load Methods","href":"datacollector\/UserGuide\/Destinations\/DeltaLake.html#concept_xcn_ymg_dlb","attributes": {"data-id":"concept_xcn_ymg_dlb",},"menu": {"hasChildren":true,},"tocID":"concept_xcn_ymg_dlb-d46e145673","next":"concept_xcn_ymg_dlb-d46e145673",},{"title":"Specifying Tables","shortdesc":"\n               <p class=\"shortdesc\">You can use the Databricks Delta Lake destination to write to one or more tables. The         destination writes data from\n                  record fields to the table columns based on matching names. \n               </p>\n            ","href":"datacollector\/UserGuide\/Destinations\/DeltaLake.html#concept_snl_cfc_2lb","attributes": {"data-id":"concept_snl_cfc_2lb",},"menu": {"hasChildren":false,},"tocID":"concept_snl_cfc_2lb-d46e145849","topics":[]},{"title":"Enabling Data Drift Handling","shortdesc":"\n               <p class=\"shortdesc\">The Databricks Delta Lake destination can automatically compensate for changes in         column or table requirements, also\n                  known as <em class=\"ph i\">data drift</em>.\n               </p>\n            ","href":"datacollector\/UserGuide\/Destinations\/DeltaLake.html#concept_ckh_wcd_2lb","attributes": {"data-id":"concept_ckh_wcd_2lb",},"menu": {"hasChildren":false,},"tocID":"concept_ckh_wcd_2lb-d46e145955","topics":[]},{"title":"Performance Optimization","href":"datacollector\/UserGuide\/Destinations\/DeltaLake.html#concept_e2g_2gs_2lb","attributes": {"data-id":"concept_e2g_2gs_2lb",},"menu": {"hasChildren":false,},"tocID":"concept_e2g_2gs_2lb-d46e146074","topics":[]},{"title":"Staging Location","shortdesc":"\n               <p class=\"shortdesc\">The Databricks Delta Lake destination first stages the pipeline data in text files in         Amazon S3 or Azure Data Lake\n                  Storage Gen2. Then, the destination sends  the COPY or MERGE         command to Databricks to process the staged files. \n               </p>\n            ","href":"datacollector\/UserGuide\/Destinations\/DeltaLake.html#concept_yms_p4v_dlb","attributes": {"data-id":"concept_yms_p4v_dlb",},"menu": {"hasChildren":true,},"tocID":"concept_yms_p4v_dlb-d46e146197","next":"concept_yms_p4v_dlb-d46e146197",},{"title":"Row Generation","shortdesc":"\n               <p class=\"shortdesc\">When writing a record to a table, the Databricks Delta Lake destination includes all         record fields in the resulting\n                  row, by default. The destination uses the root field,             <code class=\"ph codeph\">\/</code>, as the basis for the resulting row.\n               </p>\n            ","href":"datacollector\/UserGuide\/Destinations\/DeltaLake.html#concept_qmj_xld_2lb","attributes": {"data-id":"concept_qmj_xld_2lb",},"menu": {"hasChildren":true,},"tocID":"concept_qmj_xld_2lb-d46e146635","next":"concept_qmj_xld_2lb-d46e146635",},{"title":"Databricks Data Types","href":"datacollector\/UserGuide\/Destinations\/DeltaLake.html#concept_izy_zks_2lb","attributes": {"data-id":"concept_izy_zks_2lb",},"menu": {"hasChildren":false,},"tocID":"concept_izy_zks_2lb-d46e146981","topics":[]},{"title":"Configuring a Databricks Delta Lake Destination","href":"datacollector\/UserGuide\/Destinations\/DeltaLake.html#task_bv5_3wz_vkb","attributes": {"data-id":"task_bv5_3wz_vkb",},"menu": {"hasChildren":false,},"tocID":"task_bv5_3wz_vkb-d46e147164","topics":[]}]});